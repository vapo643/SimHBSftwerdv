# Runbook: Alerta de Job na Dead Letter Queue (DLQ)

## Objetivo
Plano de aÃ§Ã£o para quando jobs crÃ­ticos do sistema Simpix sÃ£o enviados para a Dead Letter Queue (DLQ), indicando falhas sistemÃ¡ticas de processamento.

## CritÃ©rios de AtivaÃ§Ã£o
- **Dashboard Alert:** DLQ contÃ©m > 5 jobs
- **Critical Jobs:** Jobs de tipos crÃ­ticos (`payments`, `notifications`, `ccb_generation`) na DLQ
- **Manual:** UsuÃ¡rios reportando funcionalidades nÃ£o executadas

## â±ï¸ SLA de Resposta
- **DetecÃ§Ã£o:** MÃ¡ximo 10 minutos
- **AnÃ¡lise Inicial:** MÃ¡ximo 20 minutos  
- **ResoluÃ§Ã£o:** MÃ¡ximo 60 minutos

---

## ðŸŽ¯ FASE 1: TRIAGEM E CLASSIFICAÃ‡ÃƒO (0-10min)

### 1.1 Acessar Dashboard de Filas
**URL:** `/admin/queues`
**LocalizaÃ§Ã£o:** SeÃ§Ã£o "Dead Letter Queue"

### 1.2 Classificar Jobs por Criticidade

#### ðŸ”´ **CRÃTICOS** (AÃ§Ã£o Imediata):
- `payments` - Processamento de pagamentos
- `ccb_generation` - GeraÃ§Ã£o de contratos CCB
- `notifications` - NotificaÃ§Ãµes obrigatÃ³rias
- `backup_data` - Backup de dados crÃ­ticos

#### ðŸŸ¡ **IMPORTANTES** (AÃ§Ã£o em 30min):
- `email_marketing` - Emails promocionais
- `report_generation` - RelatÃ³rios de gestÃ£o
- `data_sync` - SincronizaÃ§Ã£o de dados

#### ðŸŸ¢ **BAIXA PRIORIDADE** (AÃ§Ã£o em 2h):
- `cleanup_tasks` - Limpeza de dados temporÃ¡rios
- `analytics_processing` - Processamento de mÃ©tricas
- `log_rotation` - RotaÃ§Ã£o de logs

### 1.3 Coletar InformaÃ§Ãµes dos Jobs
Para cada job na DLQ:

```json
{
  "jobId": "[ID_DO_JOB]",
  "jobType": "[TIPO]", 
  "attemptsMade": "[NÃšMERO]",
  "lastError": "[MENSAGEM_ERRO]",
  "originalData": "[PAYLOAD]",
  "failedAt": "[TIMESTAMP]"
}
```

---

## ðŸ” FASE 2: ANÃLISE DE CAUSA RAIZ (10-20min)

### 2.1 AnÃ¡lise de PadrÃµes de Falha

#### Verificar Tipos de Erro Comuns:

**ðŸ”Œ Erros de Conectividade:**
```
BUSCAR POR:
- "Connection timeout"
- "ECONNREFUSED" 
- "Network unreachable"
- "DNS resolution failed"
```
**AÃ§Ã£o:** Verificar conectividade com serviÃ§os externos

**ðŸ’¾ Erros de Banco de Dados:**
```
BUSCAR POR:
- "relation does not exist"
- "duplicate key value"
- "connection terminated"
- "too many connections"
```
**AÃ§Ã£o:** Verificar integridade e status do PostgreSQL

**ðŸ“Š Erros de Dados:**
```
BUSCAR POR:
- "ValidationError"
- "invalid input syntax"  
- "null value in column"
- "foreign key constraint"
```
**AÃ§Ã£o:** Validar integridade dos dados de entrada

**ðŸ” Erros de AutenticaÃ§Ã£o:**
```
BUSCAR POR:
- "Unauthorized"
- "Invalid token"
- "Authentication failed"
- "Forbidden"
```
**AÃ§Ã£o:** Verificar tokens e credenciais de APIs

### 2.2 Verificar Logs Correlacionados
```bash
# Buscar logs do perÃ­odo de falha
grep -A 10 -B 5 "[JOB_ID]" logs/combined.log

# Verificar erros relacionados ao tipo de job
grep -i "[JOB_TYPE]" logs/combined.log | tail -20
```

### 2.3 Verificar Status de ServiÃ§os Dependentes
```bash
# Testar conectividade Supabase
curl -f $SUPABASE_URL/rest/v1/ || echo "SUPABASE DOWN"

# Testar APIs externas crÃ­ticas
curl -f https://clicksign.com/api/health || echo "CLICKSIGN DOWN"

# Verificar Redis (se aplicÃ¡vel)
redis-cli ping || echo "REDIS DOWN"
```

---

## âš™ï¸ FASE 3: DECISÃƒO DE REPROCESSAMENTO (20-40min)

### 3.1 Matriz de DecisÃ£o

| Tipo de Erro | Reprocessar? | AÃ§Ã£o |
|--------------|-------------|------|
| Timeout/Conectividade | âœ… SIM | Retry apÃ³s verificar serviÃ§o |
| Erro de Dados TemporÃ¡rio | âœ… SIM | Corrigir dados e retry |
| Erro de Schema/CÃ³digo | âŒ NÃƒO | Escalar para desenvolvimento |
| Erro de ConfiguraÃ§Ã£o | âœ… SIM | Corrigir config e retry |
| Erro de AutenticaÃ§Ã£o | âœ… SIM | Atualizar tokens e retry |
| Dados Corrompidos | âŒ NÃƒO | Marcar como falha permanente |

### 3.2 CritÃ©rios para Descarte Definitivo

**âŒ DESCARTAR SE:**
- Job tem > 5 tentativas falhadas
- Erro indica problema estrutural de cÃ³digo
- Dados de entrada sÃ£o invÃ¡lidos/corrompidos
- Job expirou (> 24h para jobs crÃ­ticos, > 7 dias para nÃ£o-crÃ­ticos)
- ServiÃ§o de destino foi descontinuado

### 3.3 Processo de ValidaÃ§Ã£o Antes do Reprocessamento

**Para Jobs CRÃTICOS:**
```bash
# Validar integridade dos dados
echo "SELECT * FROM propostas WHERE id='[PROPOSAL_ID]';" | psql $DATABASE_URL

# Verificar dependÃªncias
echo "SELECT * FROM users WHERE id='[USER_ID]';" | psql $DATABASE_URL

# Testar conectividade do serviÃ§o de destino
curl -f [ENDPOINT_DE_DESTINO]/health
```

---

## ðŸ”„ FASE 4: REPROCESSAMENTO (40-60min)

### 4.1 Reprocessamento via Dashboard

**Passos no Dashboard `/admin/queues`:**
1. Selecionar job na DLQ
2. Clicar em "View Details"
3. Verificar payload e erro
4. Clicar em "Retry Job"
5. Confirmar operaÃ§Ã£o

### 4.2 Reprocessamento Manual (Casos Especiais)

**Para Jobs de Pagamento:**
```typescript
// Exemplo de reprocessamento manual
const jobData = {
  propostaId: "[ID]",
  valor: "[VALOR]", 
  metodoPagamento: "[MÃ‰TODO]"
};

// Re-adicionar Ã  fila
await paymentQueue.add('processPayment', jobData, {
  attempts: 3,
  backoff: 'exponential'
});
```

### 4.3 Monitoramento PÃ³s-Reprocessamento

**Aguardar 10-15 minutos e verificar:**
- [ ] Job saiu da DLQ
- [ ] Job foi processado com sucesso
- [ ] NÃ£o gerou novos erros nos logs
- [ ] Funcionalidade esperada foi executada

---

## ðŸ“Š FASE 5: DOCUMENTAÃ‡ÃƒO E PREVENÃ‡ÃƒO (60+min)

### 5.1 Registro do Incidente

**Template de DocumentaÃ§Ã£o:**
```markdown
INCIDENTE DLQ - [DATA] - [HORÃRIO]
================================

JOBS AFETADOS:
- Tipo: [TIPO_JOB]
- Quantidade: [NÃšMERO] 
- PerÃ­odo: [TIMESTAMP_INÃCIO] - [TIMESTAMP_FIM]

CAUSA RAIZ:
[DESCRIÃ‡ÃƒO DA CAUSA IDENTIFICADA]

RESOLUÃ‡ÃƒO APLICADA:
â–¡ Reprocessamento automÃ¡tico
â–¡ CorreÃ§Ã£o de dados
â–¡ CorreÃ§Ã£o de configuraÃ§Ã£o
â–¡ EscalaÃ§Ã£o para desenvolvimento
â–¡ Descarte justificado

JOBS REPROCESSADOS: [X] de [Y]
JOBS DESCARTADOS: [X] de [Y]

PREVENÃ‡ÃƒO:
[MEDIDAS TOMADAS PARA EVITAR REINCIDÃŠNCIA]
```

### 5.2 Medidas Preventivas

**Baseado no Tipo de Falha:**

**Para Falhas de Conectividade:**
- Implementar circuit breaker
- Aumentar timeout de conexÃ£o
- Adicionar retry com backoff exponencial

**Para Falhas de Dados:**
- Melhorar validaÃ§Ã£o de entrada
- Implementar sanitizaÃ§Ã£o de dados
- Adicionar logs de auditoria

**Para Falhas de Recursos:**
- Monitorar utilizaÃ§Ã£o de memÃ³ria/CPU
- Implementar rate limiting
- Otimizar queries pesadas

---

## ðŸš¨ ESCALAÃ‡ÃƒO PARA DESENVOLVIMENTO

### CritÃ©rios de EscalaÃ§Ã£o:
1. **> 20 jobs crÃ­ticos** na DLQ
2. **Erro estrutural** de cÃ³digo identificado
3. **Falha sistemÃ¡tica** afetando mÃºltiplos tipos de job
4. **Perda de dados** ou corrupÃ§Ã£o detectada

### Template de EscalaÃ§Ã£o:
```
SUBJECT: [CRÃTICO] Jobs Falhando em Massa - DLQ Alert

SITUAÃ‡ÃƒO:
- Jobs na DLQ: [NÃšMERO]
- Tipos CrÃ­ticos Afetados: [LISTA]
- DuraÃ§Ã£o do Problema: [TEMPO]
- Impacto Estimado: [DESCRIÃ‡ÃƒO]

ANÃLISE TÃ‰CNICA:
- Erro Predominante: [MENSAGEM]
- PadrÃ£o Identificado: [PADRÃƒO]
- ServiÃ§os Afetados: [LISTA]

LOGS RELEVANTES:
[INSERIR EXCERPT DOS LOGS COM TIMESTAMPS]

JOBS EM RISCO:
[LISTA DE JOBS QUE PODEM SER PERDIDOS]

TENTATIVAS DE RESOLUÃ‡ÃƒO:
â–¡ [LISTA DE AÃ‡Ã•ES JÃ EXECUTADAS]

SOLICITAÃ‡ÃƒO:
â–¡ AnÃ¡lise de cÃ³digo urgente
â–¡ CorreÃ§Ã£o de bug crÃ­tico
â–¡ RevisÃ£o de arquitetura
â–¡ Rollback de deploy recente

PRIORIDADE: CRÃTICA
```

---

## ðŸ“š REFERÃŠNCIAS RÃPIDAS

### Comandos de DiagnÃ³stico:
```bash
# Verificar status geral das filas
curl -s http://localhost:5000/admin/queues/stats

# Contar jobs na DLQ
redis-cli llen "bull:simpix:failed" 2>/dev/null || echo "N/A"

# Logs de jobs falhados
grep "Job.*failed" logs/combined.log | tail -10
```

### Jobs CrÃ­ticos do Sistema:
- **payments** â†’ Affect revenue directly
- **ccb_generation** â†’ Legal compliance required  
- **notifications** â†’ User experience impact
- **backup_data** â†’ Data integrity risk

### Thresholds de Alerta:
- **0-5 jobs DLQ:** Normal
- **6-15 jobs DLQ:** Monitorar de perto
- **16-50 jobs DLQ:** InvestigaÃ§Ã£o ativa
- **50+ jobs DLQ:** EscalaÃ§Ã£o imediata