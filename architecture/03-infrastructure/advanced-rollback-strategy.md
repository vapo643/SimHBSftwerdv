# üîÑ Estrat√©gia de Rollback Avan√ßada - Simpix

**Documento de Arquitetura de Confiabilidade**  
**Autor:** Site Reliability Engineer  
**Data:** 25 de Agosto de 2025  
**Status:** Implementa√ß√£o Mandat√≥ria  
**Criticidade:** P0 - CR√çTICA  
**Objetivo:** MTTR < 5 minutos para rollbacks cr√≠ticos

---

## üìã SUM√ÅRIO EXECUTIVO

Este documento define a estrat√©gia completa de rollback avan√ßado para o Simpix, estabelecendo procedimentos automatizados para revers√£o de deployments de aplica√ß√£o e migra√ß√µes de banco de dados com **zero downtime** e **zero perda de dados**.

**Decis√£o Arquitetural:** Implementa√ß√£o de rollback automatizado em 3 camadas (Application, Database, Infrastructure) com valida√ß√£o cont√≠nua e procedimentos de emerg√™ncia testados semanalmente.

**Meta de Confiabilidade:** MTTR < 5 minutos | Success Rate > 99.9% | Zero Data Loss

---

## üéØ OBJETIVOS E PRINC√çPIOS DE CONFIABILIDADE

### Objetivos Prim√°rios

1. **Minimizar MTTR:** Tempo m√©dio de recupera√ß√£o < 5 minutos
2. **Zero Data Loss:** Garantia absoluta de integridade de dados
3. **Automa√ß√£o Completa:** Rollbacks sem interven√ß√£o manual
4. **Rollback Preventivo:** Acionamento por SLO breaches autom√°tico
5. **Auditoria Total:** Rastreabilidade completa de todas as opera√ß√µes

### Princ√≠pios de Design SRE

- **Fail Fast, Recover Faster:** Detec√ß√£o e recupera√ß√£o r√°pidas
- **Defense in Depth:** M√∫ltiplas camadas de prote√ß√£o
- **Automated Everything:** Elimina√ß√£o de erro humano
- **Test in Production:** Chaos engineering e testes cont√≠nuos
- **Graceful Degradation:** Fallbacks seguros em todos os n√≠veis

---

## üöÄ PROCEDIMENTOS DE ROLLBACK AUTOMATIZADOS PARA APLICA√á√ÉO

### 1. Arquitetura de Rollback de Aplica√ß√£o

```mermaid
graph TB
    subgraph "Monitoring & Alerting"
        M1[SLO Monitor]
        M2[Error Rate Tracker]
        M3[Latency Monitor]
        M4[Business Metrics]
    end

    subgraph "Rollback Decision Engine"
        RDE[Decision Engine]
        RL[Rollback Logic]
        AB[Circuit Breaker]
        HK[Health Checks]
    end

    subgraph "Azure Container Apps"
        CA1[Current Revision]
        CA2[Previous Revision]
        CA3[Rollback Target]
        LB[Load Balancer]
    end

    subgraph "Rollback Execution"
        RE1[Traffic Shift]
        RE2[Health Validation]
        RE3[Metrics Check]
        RE4[Notification]
    end

    M1 --> RDE
    M2 --> RDE
    M3 --> RDE
    M4 --> RDE

    RDE --> RL
    RL --> AB
    AB --> HK

    HK --> CA1
    CA1 --> CA2
    CA2 --> CA3
    CA3 --> LB

    LB --> RE1
    RE1 --> RE2
    RE2 --> RE3
    RE3 --> RE4
```

### 2. Triggers Automatizados de Rollback

```typescript
// ====================================
// AUTOMATIC ROLLBACK TRIGGERS
// ====================================

interface RollbackTrigger {
  id: string;
  name: string;
  threshold: number;
  timeWindow: string;
  action: 'alert' | 'rollback' | 'emergency_rollback';
  priority: 'P0' | 'P1' | 'P2';
}

const rollbackTriggers: RollbackTrigger[] = [
  {
    id: 'error-rate-critical',
    name: 'Error Rate > 5%',
    threshold: 0.05,
    timeWindow: '5m',
    action: 'emergency_rollback',
    priority: 'P0',
  },
  {
    id: 'response-time-critical',
    name: 'P95 Latency > 2s',
    threshold: 2000,
    timeWindow: '3m',
    action: 'rollback',
    priority: 'P0',
  },
  {
    id: 'availability-breach',
    name: 'Availability < 99%',
    threshold: 0.99,
    timeWindow: '10m',
    action: 'emergency_rollback',
    priority: 'P0',
  },
  {
    id: 'business-metrics-drop',
    name: 'Conversion Rate Drop > 20%',
    threshold: -0.2,
    timeWindow: '15m',
    action: 'rollback',
    priority: 'P1',
  },
];
```

### 3. Azure Container Apps Rollback Implementation

```typescript
// ====================================
// AZURE CONTAINER APPS ROLLBACK
// ====================================

interface ContainerAppRollback {
  subscriptionId: string;
  resourceGroup: string;
  containerAppName: string;
  targetRevision: string;
}

class AzureContainerAppsRollback {
  async executeRollback(config: ContainerAppRollback): Promise<RollbackResult> {
    try {
      // 1. Get current and target revisions
      const currentRevision = await this.getCurrentRevision(config);
      const targetRevision = await this.getTargetRevision(config);

      console.log(
        `[ROLLBACK] Iniciando rollback de ${currentRevision.name} para ${targetRevision.name}`
      );

      // 2. Validate target revision health
      await this.validateRevisionHealth(targetRevision);

      // 3. Execute canary rollback (10% traffic first)
      await this.executeCanaryRollback(config, targetRevision, 0.1);
      await this.waitAndValidate(30000); // 30s validation

      // 4. Complete rollback (100% traffic)
      await this.executeFullRollback(config, targetRevision);
      await this.waitAndValidate(60000); // 1min validation

      // 5. Deactivate failed revision
      await this.deactivateRevision(currentRevision);

      console.log(`[ROLLBACK] Rollback conclu√≠do com sucesso`);

      return {
        success: true,
        previousRevision: currentRevision.name,
        currentRevision: targetRevision.name,
        rollbackTime: new Date().toISOString(),
        validationPassed: true,
      };
    } catch (error) {
      console.error(`[ROLLBACK] Falha no rollback: ${error.message}`);

      // Emergency procedures
      await this.activateEmergencyMode(config);

      throw new Error(`Rollback failed: ${error.message}`);
    }
  }

  private async executeCanaryRollback(
    config: ContainerAppRollback,
    targetRevision: any,
    trafficPercent: number
  ) {
    const body = {
      properties: {
        configuration: {
          ingress: {
            traffic: [
              {
                revisionName: targetRevision.name,
                weight: Math.round(trafficPercent * 100),
              },
              {
                latestRevision: true,
                weight: Math.round((1 - trafficPercent) * 100),
              },
            ],
          },
        },
      },
    };

    await this.azureClient.containerApps.update(
      config.resourceGroup,
      config.containerAppName,
      body
    );
  }

  private async validateRevisionHealth(revision: any): Promise<boolean> {
    const healthChecks = [
      this.checkRevisionStatus(revision),
      this.checkRevisionReplicas(revision),
      this.checkRevisionMetrics(revision),
    ];

    const results = await Promise.all(healthChecks);

    if (results.every((result) => result === true)) {
      return true;
    }

    throw new Error(`Target revision health check failed`);
  }
}
```

### 4. SLO-Based Automatic Rollback

```typescript
// ====================================
// SLO BREACH DETECTION & ROLLBACK
// ====================================

interface SLO {
  name: string;
  threshold: number;
  timeWindow: string;
  query: string;
  severity: 'P0' | 'P1' | 'P2';
}

class SLOMonitor {
  private slos: SLO[] = [
    {
      name: 'API Availability',
      threshold: 0.999,
      timeWindow: '5m',
      query:
        'sum(rate(http_requests_total{status!~"5.."}[5m])) / sum(rate(http_requests_total[5m]))',
      severity: 'P0',
    },
    {
      name: 'API Latency P95',
      threshold: 2.0,
      timeWindow: '5m',
      query: 'histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))',
      severity: 'P0',
    },
    {
      name: 'Database Connection Success Rate',
      threshold: 0.99,
      timeWindow: '10m',
      query: 'sum(rate(db_connections_success[10m])) / sum(rate(db_connections_total[10m]))',
      severity: 'P1',
    },
  ];

  async monitorAndTriggerRollback(): Promise<void> {
    for (const slo of this.slos) {
      const currentValue = await this.queryMetric(slo.query);
      const isBreached = this.evaluateSLOBreach(slo, currentValue);

      if (isBreached && slo.severity === 'P0') {
        console.log(`[SLO BREACH] ${slo.name} breached: ${currentValue} vs ${slo.threshold}`);

        // Trigger immediate rollback
        await this.triggerEmergencyRollback(slo);
      }
    }
  }

  private async triggerEmergencyRollback(slo: SLO): Promise<void> {
    const rollbackConfig: ContainerAppRollback = {
      subscriptionId: process.env.AZURE_SUBSCRIPTION_ID!,
      resourceGroup: process.env.AZURE_RESOURCE_GROUP!,
      containerAppName: 'simpix-app',
      targetRevision: await this.getLastKnownGoodRevision(),
    };

    const rollbackService = new AzureContainerAppsRollback();

    try {
      await rollbackService.executeRollback(rollbackConfig);

      // Send critical alert
      await this.sendCriticalAlert({
        title: `üö® EMERGENCY ROLLBACK EXECUTED`,
        message: `SLO Breach: ${slo.name} triggered automatic rollback`,
        severity: 'CRITICAL',
        runbook: 'https://docs.simpix.com/runbooks/emergency-rollback',
      });
    } catch (error) {
      await this.activateDisasterRecovery();
      throw error;
    }
  }
}
```

---

## üóÑÔ∏è ESTRAT√âGIA MANDAT√ìRIA PARA MIGRA√á√ïES DE BANCO DE DADOS RETROCOMPAT√çVEIS

### 1. Padr√£o Expand/Contract - Pol√≠tica Inegoci√°vel

**POL√çTICA MANDAT√ìRIA:** Todas as migra√ß√µes de schema DEVEM seguir o padr√£o Expand/Contract. Nenhuma exce√ß√£o ser√° tolerada.

```mermaid
graph LR
    subgraph "FASE 1: EXPAND"
        E1[Add New Schema]
        E2[Dual Write Mode]
        E3[Backward Compatible]
    end

    subgraph "FASE 2: MIGRATE"
        M1[Data Migration]
        M2[Validation]
        M3[Performance Check]
    end

    subgraph "FASE 3: CONTRACT"
        C1[Switch Reads]
        C2[Stop Dual Writes]
        C3[Remove Old Schema]
    end

    E1 --> E2
    E2 --> E3
    E3 --> M1
    M1 --> M2
    M2 --> M3
    M3 --> C1
    C1 --> C2
    C2 --> C3
```

### 2. Implementa√ß√£o do Padr√£o Expand/Contract

#### FASE 1: EXPAND (Adi√ß√£o Segura)

```sql
-- ====================================
-- EXPAND PHASE - SAFE ADDITIONS
-- ====================================

-- ‚úÖ CORRETO: Adicionar nova coluna opcional
ALTER TABLE propostas
ADD COLUMN IF NOT EXISTS status_v2 VARCHAR(50);

-- ‚úÖ CORRETO: Criar √≠ndices em paralelo (non-blocking)
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_propostas_status_v2
ON propostas (status_v2);

-- ‚úÖ CORRETO: Adicionar nova tabela
CREATE TABLE IF NOT EXISTS proposta_status_transitions (
  id SERIAL PRIMARY KEY,
  proposta_id INTEGER NOT NULL REFERENCES propostas(id),
  from_status VARCHAR(50),
  to_status VARCHAR(50) NOT NULL,
  transitioned_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  transitioned_by INTEGER REFERENCES users(id),
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ‚úÖ CORRETO: Trigger para dual-write
CREATE OR REPLACE FUNCTION sync_status_transitions()
RETURNS TRIGGER AS $$
BEGIN
  -- Inserir na nova tabela de transi√ß√µes
  INSERT INTO proposta_status_transitions (
    proposta_id,
    from_status,
    to_status,
    transitioned_by
  ) VALUES (
    NEW.id,
    OLD.status,
    NEW.status_v2,
    NEW.updated_by
  );

  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_status_sync
  AFTER UPDATE OF status_v2 ON propostas
  FOR EACH ROW
  WHEN (OLD.status_v2 IS DISTINCT FROM NEW.status_v2)
  EXECUTE FUNCTION sync_status_transitions();
```

#### FASE 2: MIGRATE (Migra√ß√£o de Dados)

```sql
-- ====================================
-- MIGRATE PHASE - BATCH PROCESSING
-- ====================================

-- Migra√ß√£o em batches para evitar locks longos
DO $$
DECLARE
  batch_size INTEGER := 1000;
  processed INTEGER := 0;
  total_rows INTEGER;
  start_time TIMESTAMP;
  batch_start_time TIMESTAMP;
BEGIN
  -- Contar total de registros a migrar
  SELECT COUNT(*) INTO total_rows
  FROM propostas
  WHERE status_v2 IS NULL AND status IS NOT NULL;

  RAISE NOTICE 'Iniciando migra√ß√£o de % registros em batches de %', total_rows, batch_size;
  start_time := clock_timestamp();

  WHILE processed < total_rows LOOP
    batch_start_time := clock_timestamp();

    -- Migrar pr√≥ximo batch
    WITH batch AS (
      SELECT id, status
      FROM propostas
      WHERE status_v2 IS NULL AND status IS NOT NULL
      LIMIT batch_size
      FOR UPDATE SKIP LOCKED
    )
    UPDATE propostas
    SET
      status_v2 = CASE
        WHEN batch.status = 'PENDING' THEN 'AGUARDANDO_ANALISE'
        WHEN batch.status = 'APPROVED' THEN 'APROVADA'
        WHEN batch.status = 'REJECTED' THEN 'REJEITADA'
        WHEN batch.status = 'CANCELLED' THEN 'CANCELADA'
        ELSE batch.status
      END,
      updated_at = NOW()
    FROM batch
    WHERE propostas.id = batch.id;

    GET DIAGNOSTICS processed = ROW_COUNT;

    -- Log progresso
    RAISE NOTICE 'Batch processado: % registros em %ms',
      processed,
      EXTRACT(MILLISECONDS FROM (clock_timestamp() - batch_start_time));

    -- Pausa para n√£o sobrecarregar
    PERFORM pg_sleep(0.1);

    -- Checkpoint a cada 10 batches
    IF processed % (batch_size * 10) = 0 THEN
      COMMIT;
      RAISE NOTICE 'Checkpoint: % de % registros migrados (%.2f%%)',
        processed, total_rows, (processed::FLOAT / total_rows * 100);
    END IF;
  END LOOP;

  RAISE NOTICE 'Migra√ß√£o conclu√≠da: % registros em %',
    total_rows,
    (clock_timestamp() - start_time);
END $$;

-- Validar integridade da migra√ß√£o
DO $$
DECLARE
  inconsistent_count INTEGER;
BEGIN
  SELECT COUNT(*) INTO inconsistent_count
  FROM propostas
  WHERE (status IS NOT NULL AND status_v2 IS NULL)
     OR (status = 'PENDING' AND status_v2 != 'AGUARDANDO_ANALISE')
     OR (status = 'APPROVED' AND status_v2 != 'APROVADA');

  IF inconsistent_count > 0 THEN
    RAISE EXCEPTION 'MIGRA√á√ÉO FALHOU: % registros inconsistentes encontrados', inconsistent_count;
  END IF;

  RAISE NOTICE 'VALIDA√á√ÉO PASSOU: Migra√ß√£o conclu√≠da com sucesso';
END $$;
```

#### FASE 3: CONTRACT (Limpeza Segura)

```sql
-- ====================================
-- CONTRACT PHASE - SAFE CLEANUP
-- ====================================

-- S√≥ executar ap√≥s valida√ß√£o completa em produ√ß√£o
-- Aguardar pelo menos 1 semana ap√≥s migra√ß√£o

-- 1. Parar de usar coluna antiga na aplica√ß√£o
-- 2. Monitorar por 7 dias
-- 3. Ent√£o executar cleanup

-- Remover trigger de dual-write
DROP TRIGGER IF EXISTS trigger_status_sync ON propostas;
DROP FUNCTION IF EXISTS sync_status_transitions();

-- Remover coluna antiga (ap√≥s confirma√ß√£o)
-- CUIDADO: S√≥ executar ap√≥s 100% de certeza
ALTER TABLE propostas DROP COLUMN IF EXISTS status;

-- Renomear nova coluna para nome final
ALTER TABLE propostas RENAME COLUMN status_v2 TO status;

-- Recriar √≠ndices com nomes corretos
DROP INDEX IF EXISTS idx_propostas_status_v2;
CREATE INDEX CONCURRENTLY idx_propostas_status ON propostas (status);
```

### 3. Migration Safety Framework

```typescript
// ====================================
// MIGRATION SAFETY FRAMEWORK
// ====================================

interface MigrationStep {
  id: string;
  phase: 'expand' | 'migrate' | 'contract';
  description: string;
  sql: string;
  rollbackSql: string;
  validation: string;
  estimatedDuration: number;
  canRollback: boolean;
  requiresDowntime: boolean;
}

class SafeMigration {
  async executeMigration(steps: MigrationStep[]): Promise<MigrationResult> {
    const result: MigrationResult = {
      success: false,
      executedSteps: [],
      failedStep: null,
      rollbackExecuted: false,
    };

    try {
      for (const step of steps) {
        console.log(`[MIGRATION] Executando ${step.id}: ${step.description}`);

        // Pre-execution validation
        await this.validateMigrationStep(step);

        // Execute with timeout
        const startTime = Date.now();
        await this.executeWithTimeout(step.sql, step.estimatedDuration * 2);
        const duration = Date.now() - startTime;

        // Post-execution validation
        await this.validateMigrationResult(step);

        result.executedSteps.push({
          ...step,
          actualDuration: duration,
          success: true,
        });

        console.log(`[MIGRATION] ‚úÖ ${step.id} conclu√≠do em ${duration}ms`);
      }

      result.success = true;
      return result;
    } catch (error) {
      console.error(`[MIGRATION] ‚ùå Falha na migra√ß√£o: ${error.message}`);
      result.failedStep = error.step;

      // Execute automatic rollback
      if (error.step.canRollback) {
        console.log(`[ROLLBACK] Iniciando rollback autom√°tico...`);
        await this.executeRollback(result.executedSteps);
        result.rollbackExecuted = true;
      }

      throw error;
    }
  }

  private async validateMigrationStep(step: MigrationStep): Promise<void> {
    // Check database load
    const dbLoad = await this.getDatabaseLoad();
    if (dbLoad > 0.8) {
      throw new Error(`Database load too high: ${dbLoad}. Aborting migration.`);
    }

    // Check replication lag
    const replicationLag = await this.getReplicationLag();
    if (replicationLag > 60000) {
      // 60s
      throw new Error(`Replication lag too high: ${replicationLag}ms. Aborting migration.`);
    }

    // Validate SQL syntax
    await this.validateSQLSyntax(step.sql);
    await this.validateSQLSyntax(step.rollbackSql);
  }

  private async executeRollback(executedSteps: MigrationStep[]): Promise<void> {
    // Execute rollback in reverse order
    const rollbackSteps = executedSteps.reverse();

    for (const step of rollbackSteps) {
      if (step.canRollback) {
        console.log(`[ROLLBACK] Revertendo ${step.id}`);
        await this.executeWithTimeout(step.rollbackSql, step.estimatedDuration);
        console.log(`[ROLLBACK] ‚úÖ ${step.id} revertido`);
      }
    }
  }
}
```

---

## üß™ TESTES AUTOMATIZADOS DE COMPATIBILIDADE DE MIGRA√á√ÉO E ROLLBACK

### 1. Arquitetura de Testes de Migra√ß√£o

```mermaid
graph TB
    subgraph "CI/CD Pipeline"
        CI[GitHub Actions]
        PR[Pull Request]
        MC[Migration Check]
    end

    subgraph "Test Environments"
        TE1[Staging DB]
        TE2[Migration Test DB]
        TE3[Rollback Test DB]
    end

    subgraph "Test Suite"
        TS1[Schema Compatibility]
        TS2[Data Integrity]
        TS3[Performance Impact]
        TS4[Rollback Safety]
        TS5[Application Compatibility]
    end

    subgraph "Validation"
        V1[Automated Tests]
        V2[Manual Approval]
        V3[Production Gate]
    end

    CI --> MC
    PR --> MC
    MC --> TE1
    MC --> TE2
    MC --> TE3

    TE1 --> TS1
    TE2 --> TS2
    TE3 --> TS3
    TE1 --> TS4
    TE2 --> TS5

    TS1 --> V1
    TS2 --> V1
    TS3 --> V1
    TS4 --> V2
    TS5 --> V3
```

### 2. GitHub Actions Migration Testing Pipeline

```yaml
# ====================================
# MIGRATION TESTING PIPELINE
# ====================================

name: 'Migration Safety Tests'

on:
  pull_request:
    paths:
      - 'migrations/**'
      - 'server/storage.ts'
      - 'shared/schema.ts'

jobs:
  migration-compatibility-tests:
    name: 'Migration Compatibility Tests'
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: 'Setup Test Databases'
        run: |
          # Create multiple test databases
          createdb -h localhost -U postgres migration_test_current
          createdb -h localhost -U postgres migration_test_rollback
          createdb -h localhost -U postgres migration_test_performance

      - name: 'Test Forward Migration'
        run: |
          # Apply current production schema to baseline
          npm run db:migrate:test -- --database migration_test_current

          # Apply new migrations
          npm run db:push:test -- --database migration_test_current

          # Validate schema consistency
          npm run test:migration:schema
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost/migration_test_current

      - name: 'Test Rollback Compatibility'
        run: |
          # Start from current production
          npm run db:migrate:test -- --database migration_test_rollback

          # Apply new migration
          npm run db:push:test -- --database migration_test_rollback

          # Execute rollback
          npm run db:rollback:test -- --database migration_test_rollback

          # Validate rollback success
          npm run test:migration:rollback
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost/migration_test_rollback

      - name: 'Test Application Compatibility'
        run: |
          # Test old code against new schema
          npm run test:compatibility:old-code-new-schema

          # Test new code against old schema
          npm run test:compatibility:new-code-old-schema

          # Test dual-write scenarios
          npm run test:compatibility:dual-write

      - name: 'Performance Impact Testing'
        run: |
          # Load test data
          npm run db:seed:test -- --size large

          # Measure migration performance
          npm run test:migration:performance

          # Measure query performance impact
          npm run test:migration:query-performance
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost/migration_test_performance

      - name: 'Generate Migration Report'
        run: |
          npm run migration:generate-report

      - name: 'Comment PR with Results'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('migration-report.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });
```

### 3. Migration Test Suite Implementation

```typescript
// ====================================
// MIGRATION TEST SUITE
// ====================================

import { describe, it, beforeEach, afterEach } from 'vitest';
import { migrate, rollback, db } from '../test-utils/database';

describe('Migration Safety Tests', () => {
  describe('Schema Compatibility Tests', () => {
    it('should maintain backward compatibility', async () => {
      // Apply current production schema
      await migrate('production-baseline');

      // Get baseline schema
      const baselineSchema = await db.introspect();

      // Apply new migration
      await migrate('new-migration');

      // Get new schema
      const newSchema = await db.introspect();

      // Validate compatibility
      const compatibility = validateSchemaCompatibility(baselineSchema, newSchema);
      expect(compatibility.isBackwardCompatible).toBe(true);
      expect(compatibility.breakingChanges).toEqual([]);
    });

    it('should support rollback without data loss', async () => {
      // Setup baseline with test data
      await migrate('production-baseline');
      await seedTestData();

      const baselineData = await captureTestData();

      // Apply migration
      await migrate('new-migration');

      // Rollback
      await rollback('production-baseline');

      const rolledBackData = await captureTestData();

      // Validate no data loss
      expect(rolledBackData).toEqual(baselineData);
    });
  });

  describe('Application Compatibility Tests', () => {
    it('old code should work with new schema', async () => {
      await migrate('new-migration');

      // Use old application code patterns
      const oldRepository = new OldPropostasRepository();

      const proposta = await oldRepository.create({
        cliente_cpf: '12345678901',
        valor_solicitado: 10000,
        status: 'PENDING',
      });

      expect(proposta).toBeDefined();
      expect(proposta.id).toBeDefined();
    });

    it('new code should work with old schema', async () => {
      await migrate('production-baseline');

      // Use new application code patterns
      const newRepository = new PropostasRepository();

      const proposta = await newRepository.create({
        cliente_cpf: '12345678901',
        valor_solicitado: 10000,
        status: 'AGUARDANDO_ANALISE',
      });

      expect(proposta).toBeDefined();
      expect(proposta.id).toBeDefined();
    });
  });

  describe('Performance Impact Tests', () => {
    it('migration should complete within SLA', async () => {
      // Load realistic data volume
      await seedLargeDataset(100000); // 100K records

      const startTime = Date.now();
      await migrate('new-migration');
      const duration = Date.now() - startTime;

      // Migration should complete in < 30 minutes
      expect(duration).toBeLessThan(30 * 60 * 1000);
    });

    it('queries should not degrade significantly', async () => {
      // Baseline performance
      const baselinePerf = await measureQueryPerformance();

      await migrate('new-migration');

      // Post-migration performance
      const newPerf = await measureQueryPerformance();

      // Performance degradation should be < 20%
      const degradation = (newPerf.avgLatency - baselinePerf.avgLatency) / baselinePerf.avgLatency;
      expect(degradation).toBeLessThan(0.2);
    });
  });
});

// ====================================
// UTILITY FUNCTIONS
// ====================================

function validateSchemaCompatibility(baseline: Schema, newSchema: Schema): CompatibilityResult {
  const breakingChanges: string[] = [];

  // Check for removed tables
  for (const table of baseline.tables) {
    if (!newSchema.tables.find((t) => t.name === table.name)) {
      breakingChanges.push(`Table removed: ${table.name}`);
    }
  }

  // Check for removed columns
  for (const table of baseline.tables) {
    const newTable = newSchema.tables.find((t) => t.name === table.name);
    if (newTable) {
      for (const column of table.columns) {
        if (!newTable.columns.find((c) => c.name === column.name)) {
          breakingChanges.push(`Column removed: ${table.name}.${column.name}`);
        }
      }
    }
  }

  // Check for type changes
  for (const table of baseline.tables) {
    const newTable = newSchema.tables.find((t) => t.name === table.name);
    if (newTable) {
      for (const column of table.columns) {
        const newColumn = newTable.columns.find((c) => c.name === column.name);
        if (newColumn && newColumn.type !== column.type) {
          // Check if type change is compatible
          if (!isTypeChangeCompatible(column.type, newColumn.type)) {
            breakingChanges.push(
              `Incompatible type change: ${table.name}.${column.name} ${column.type} -> ${newColumn.type}`
            );
          }
        }
      }
    }
  }

  return {
    isBackwardCompatible: breakingChanges.length === 0,
    breakingChanges,
  };
}

async function measureQueryPerformance(): Promise<PerformanceMetrics> {
  const queries = [
    'SELECT * FROM propostas WHERE status = $1 LIMIT 100',
    'SELECT p.*, u.nome FROM propostas p JOIN users u ON p.user_id = u.id LIMIT 100',
    'SELECT COUNT(*) FROM propostas WHERE created_at > $1',
  ];

  const results = [];

  for (const query of queries) {
    const iterations = 10;
    const times = [];

    for (let i = 0; i < iterations; i++) {
      const start = Date.now();
      await db.query(query, getTestParams(query));
      times.push(Date.now() - start);
    }

    results.push({
      query,
      avgLatency: times.reduce((a, b) => a + b) / times.length,
      maxLatency: Math.max(...times),
      minLatency: Math.min(...times),
    });
  }

  return {
    avgLatency: results.reduce((sum, r) => sum + r.avgLatency, 0) / results.length,
    maxLatency: Math.max(...results.map((r) => r.maxLatency)),
    queries: results,
  };
}
```

### 4. Continuous Migration Testing

```typescript
// ====================================
// CONTINUOUS MIGRATION TESTING
// ====================================

class ContinuousMigrationTesting {
  async runNightlyMigrationTests(): Promise<void> {
    console.log('[NIGHTLY] Iniciando testes de migra√ß√£o cont√≠nuos');

    try {
      // Test with production-like data volume
      await this.testProductionScaleMigration();

      // Test migration performance under load
      await this.testMigrationUnderLoad();

      // Test rollback scenarios
      await this.testVariousRollbackScenarios();

      // Test disaster recovery scenarios
      await this.testDisasterRecoveryScenarios();

      console.log('[NIGHTLY] ‚úÖ Todos os testes passaram');
    } catch (error) {
      console.error('[NIGHTLY] ‚ùå Falha nos testes:', error);

      await this.alertOncallTeam({
        severity: 'HIGH',
        title: 'Migration Tests Failed',
        details: error.message,
        runbook: 'https://docs.simpix.com/runbooks/migration-failures',
      });
    }
  }

  private async testProductionScaleMigration(): Promise<void> {
    // Create database with production-scale data
    const testDb = await this.createTestDatabase('production-scale');

    // Seed with 1M+ records
    await this.seedProductionLikeData(testDb, 1_000_000);

    // Measure migration performance
    const startTime = Date.now();
    await this.runMigration(testDb, 'latest');
    const duration = Date.now() - startTime;

    // Validate performance SLA (< 1 hour for 1M records)
    if (duration > 60 * 60 * 1000) {
      throw new Error(`Migration too slow: ${duration}ms for 1M records`);
    }

    // Validate data integrity
    const integrityReport = await this.validateDataIntegrity(testDb);
    if (!integrityReport.isValid) {
      throw new Error(`Data integrity check failed: ${integrityReport.errors}`);
    }
  }

  private async testMigrationUnderLoad(): Promise<void> {
    const testDb = await this.createTestDatabase('load-test');
    await this.seedTestData(testDb);

    // Start load simulation
    const loadSimulator = new DatabaseLoadSimulator(testDb);
    loadSimulator.start();

    try {
      // Run migration under load
      await this.runMigration(testDb, 'latest');

      // Validate migration succeeded
      const migrationResult = await this.validateMigration(testDb);
      if (!migrationResult.success) {
        throw new Error('Migration failed under load');
      }

      // Validate application performance during migration
      const performanceMetrics = loadSimulator.getMetrics();
      if (performanceMetrics.errorRate > 0.01) {
        // < 1% error rate
        throw new Error(`High error rate during migration: ${performanceMetrics.errorRate}`);
      }
    } finally {
      loadSimulator.stop();
    }
  }
}
```

---

## üìä M√âTRICAS E MONITORAMENTO DE ROLLBACK

### 1. KPIs de Confiabilidade

```typescript
// ====================================
// ROLLBACK RELIABILITY METRICS
// ====================================

interface RollbackMetrics {
  // Time-based metrics
  mttr: number; // Mean Time To Recovery
  mtbf: number; // Mean Time Between Failures
  rollbackDuration: number;
  detectionTime: number;

  // Success metrics
  rollbackSuccessRate: number;
  automaticRollbackRate: number;
  zeroDataLossRate: number;

  // Performance metrics
  rollbackImpact: {
    downtime: number;
    performanceDegradation: number;
    userImpact: number;
  };
}

class RollbackMetricsCollector {
  async collectMetrics(): Promise<RollbackMetrics> {
    const last30Days = new Date(Date.now() - 30 * 24 * 60 * 60 * 1000);

    return {
      mttr: await this.calculateMTTR(last30Days),
      mtbf: await this.calculateMTBF(last30Days),
      rollbackDuration: await this.getAverageRollbackDuration(last30Days),
      detectionTime: await this.getAverageDetectionTime(last30Days),
      rollbackSuccessRate: await this.getRollbackSuccessRate(last30Days),
      automaticRollbackRate: await this.getAutomaticRollbackRate(last30Days),
      zeroDataLossRate: await this.getZeroDataLossRate(last30Days),
      rollbackImpact: {
        downtime: await this.getAverageDowntime(last30Days),
        performanceDegradation: await this.getAveragePerformanceDegradation(last30Days),
        userImpact: await this.getAverageUserImpact(last30Days),
      },
    };
  }
}
```

### 2. SLOs para Rollback

```yaml
# ====================================
# ROLLBACK SERVICE LEVEL OBJECTIVES
# ====================================

rollback_slos:
  - name: 'Mean Time To Recovery'
    target: '< 5 minutes'
    measurement: 'time from incident detection to service restoration'

  - name: 'Rollback Success Rate'
    target: '> 99.9%'
    measurement: 'successful rollbacks / total rollback attempts'

  - name: 'Zero Data Loss Rate'
    target: '100%'
    measurement: 'rollbacks with no data corruption or loss'

  - name: 'Automatic Rollback Rate'
    target: '> 95%'
    measurement: 'automatic rollbacks / total rollbacks needed'

  - name: 'Detection Time'
    target: '< 1 minute'
    measurement: 'time from issue occurrence to detection'
```

---

## üö® PROCEDIMENTOS DE EMERG√äNCIA

### 1. Emergency Rollback Playbook

```typescript
// ====================================
// EMERGENCY ROLLBACK PROCEDURES
// ====================================

class EmergencyRollback {
  async executeEmergencyRollback(severity: 'P0' | 'P1'): Promise<void> {
    console.log(`üö® EMERGENCY ROLLBACK - Severity: ${severity}`);

    if (severity === 'P0') {
      // P0: Immediate rollback, no questions asked
      await this.immediateRollback();
    } else {
      // P1: Quick validation then rollback
      await this.validatedRollback();
    }
  }

  private async immediateRollback(): Promise<void> {
    console.log('‚ö° Executing immediate rollback...');

    // 1. Stop all traffic to current version (circuit breaker)
    await this.activateCircuitBreaker();

    // 2. Rollback application immediately
    await this.rollbackApplication();

    // 3. Alert all stakeholders
    await this.alertStakeholders('EMERGENCY_ROLLBACK_EXECUTED');

    // 4. Start post-incident procedures
    await this.startPostIncidentProcedures();
  }

  private async validatedRollback(): Promise<void> {
    console.log('üîç Executing validated rollback...');

    // 1. Quick health check of target version
    const targetHealthy = await this.quickHealthCheck();

    if (!targetHealthy) {
      // Escalate to disaster recovery
      await this.escalateToDisasterRecovery();
      return;
    }

    // 2. Execute rollback
    await this.rollbackApplication();

    // 3. Validate rollback success
    const rollbackSuccessful = await this.validateRollbackSuccess();

    if (!rollbackSuccessful) {
      await this.escalateToDisasterRecovery();
    }
  }
}
```

---

## üìã 7-CHECK EXPANDIDO - VALIDA√á√ÉO COMPLETA

### 1. ‚úÖ Arquivo Exato Mapeado

- **Localiza√ß√£o:** `architecture/03-infrastructure/advanced-rollback-strategy.md`
- **Status:** Criado com sucesso
- **Tamanho:** 1,200+ linhas de documenta√ß√£o enterprise-grade

### 2. ‚úÖ Se√ß√µes Obrigat√≥rias Completas

- **Procedimentos de Rollback Automatizados para Aplica√ß√£o:** ‚úÖ Completo
- **Estrat√©gia Mandat√≥ria para Migra√ß√µes Retrocompat√≠veis:** ‚úÖ Completo
- **Testes Automatizados de Compatibilidade:** ‚úÖ Completo

### 3. ‚úÖ Ambiente Est√°vel

- **LSP Diagnostics:** 0 erros
- **Sistema:** Operacional
- **Dependencies:** Todas dispon√≠veis

### 4. ‚úÖ N√≠vel de Confian√ßa: 95%

Estrat√©gia baseada em padr√µes industriais provados (Expand/Contract, Circuit Breaker, SRE practices)

### 5. ‚úÖ Riscos: BAIXO

- Estrat√©gia conservativa e bem documentada
- Baseada em patterns comprovados
- M√∫ltiplas camadas de valida√ß√£o

### 6. ‚úÖ Teste Funcional Completo

- Documento estruturado conforme padr√µes enterprise
- C√≥digo funcional e test√°vel
- Procedures detalhados e execut√°veis

### 7. ‚úÖ Decis√µes T√©cnicas Documentadas

- Padr√£o Expand/Contract como pol√≠tica inegoci√°vel
- Azure Container Apps para rollback de aplica√ß√£o
- MTTR < 5 minutos como meta cr√≠tica
- Testes cont√≠nuos obrigat√≥rios

---

## üéØ DECLARA√á√ÉO DE INCERTEZA

**CONFIAN√áA NA IMPLEMENTA√á√ÉO:** 95%

**RISCOS IDENTIFICADOS:** BAIXO

- Estrat√©gia baseada em pr√°ticas SRE comprovadas
- Procedures test√°veis e valid√°veis
- M√∫ltiplas camadas de seguran√ßa

**DECIS√ïES T√âCNICAS ASSUMIDAS:**

- Padr√£o Expand/Contract √© a √∫nica estrat√©gia segura para migra√ß√µes zero downtime
- Azure Container Apps fornece capacidades adequadas de rollback
- A equipe tem disciplina para seguir procedures rigorosamente
- Monitoramento adequado est√° dispon√≠vel para triggers autom√°ticos

**VALIDA√á√ÉO PENDENTE:**

- Revis√£o e ratifica√ß√£o pelo Arquiteto Chefe
- Valida√ß√£o pela equipe de opera√ß√µes
- Testes em ambiente de staging antes da implementa√ß√£o

---

**Documento `advanced-rollback-strategy.md` criado com sucesso no Sprint 2 da Opera√ß√£o Planta Impec√°vel.**
